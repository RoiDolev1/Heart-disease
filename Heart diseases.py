# -*- coding: utf-8 -*-
"""Roi Dolev 207252479 Bar Dahan 208010850

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PHhXEpvTsRF-VcDJZJ9TJdIlAnij_yWt

# Heart Disease Prediction Model

# Roi Dolev 207252479
# Bar Dahan 208010850



במחברת זו נדגים את תהליך בניית מודל לחיזוי מחלת לב באמצעות מערך נתונים. השלבים כוללים: ויזואליזציה של הנתונים, בדיקה לקיומם של ערכים חסרים, יצירת מפה חום לבדיקת הקורלציה, הנדסת תכונות, חלוקת הנתונים, בחירת מודל, כיוונון היפר-פרמטרים, והערכת המודל הטוב ביותר באמצעות מטריצת בלבול.
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
import numpy as np
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.tree import DecisionTreeClassifier
# טעינת הסט נתונים
df1 = pd.read_csv('heart.csv')

# בדיקה לערכים חסרים
null_values = df1.isnull().sum()
print(null_values)

# בדיקה האם יש שורות כפולות
num_duplicated_rows = df1.duplicated().sum()
print(f"Number of duplicated rows: {num_duplicated_rows}")

# הפעלת הפונקציה שמורידה שורות כפולות על קובץ הנתונים
df = df1.drop_duplicates()

# תצוגה של מספר השורות החדש בקובץ
num_rows_after = df.shape[0]
print(f"Number of rows after removing duplicates: {num_rows_after}")

# הכרות עם המאפיינים
print(df.head())
print(df.info())
print(df.describe())

# יצירת מטריצת קורלציה
correlation_matrix = df.corr()


# יצירת Heatmap להמחשת הקורלציות
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix Heatmap')
plt.show()

#פיצול עמודות למאפיינים ויעד
labels = df['target']
features = df.drop(columns=['target'])

# בדיקת מספר הערכים הייחודיים בכל עמודה
unique_values = {column: df[column].nunique() for column in df.columns}
print(unique_values)

# סטנדרטיזציה של הנתונים
scaler = StandardScaler()
features_scaled = scaler.fit_transform(features)
features_scaled_df = pd.DataFrame(features_scaled, columns=features.columns)

# פיצול הנתונים לסטים של אימון, בדיקה וולידציה
features_train, features_temp, labels_train, labels_temp = train_test_split(
    features_scaled_df, labels, test_size=0.3, random_state=42)

features_val, features_test, labels_val, labels_test = train_test_split(
    features_temp, labels_temp, test_size=0.5, random_state=42)

print(f'Training set size: {len(features_train)}')
print(f'Validation set size: {len(features_val)}')
print(f'Test set size: {len(features_test)}')

# הגדרת טווח הערכים להייפר-פרמטרים
param_grid = {
    'n_neighbors': [1, 3, 5, 7],
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan']
}

# יצירת מודל KNN
knn = KNeighborsClassifier()

# בדיקה על סט האימון עם הייפר פרמטרים שונים על מנת להתאים את ההייפר פרמטרים הטובים ביותר על פי ציון accuracy
grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=10, scoring='accuracy')
grid_search.fit(features_train, labels_train)

# הדפסת ההייפר-פרמטרים האופטימליים
print(f'Best Hyperparameters: {grid_search.best_params_}')
print(f'Best Accuracy: {grid_search.best_score_}')


# אימון המודל האופטימלי על סט האימון כולו
best_knn = grid_search.best_estimator_
best_knn.fit(features_train, labels_train)

# בדיקה על סט הוולידציה
labels_val_pred = best_knn.predict(features_val)
val_accuracy = accuracy_score(labels_val, labels_val_pred)
print(f'Validation Accuracy: {val_accuracy}')

# יצירת מטריצת בלבול והצגתה על סט הוולידציה
cm = confusion_matrix(labels_val, labels_val_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix - Validation Set')
plt.show()

# הגדרת טווח הערכים להייפר-פרמטרים עבור XGBoost
param_grid_xgb = {
    'n_estimators': [50, 100, 150],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.2]
}

# יצירת מודל XGBoost
xgboost_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)

# בדיקה על סט האימון עם הייפר פרמטרים שונים על מנת להתאים את ההייפר פרמטרים הטובים ביותר על פי ציון accuracy
grid_search_xgb = GridSearchCV(estimator=xgboost_model, param_grid=param_grid_xgb, cv=10, scoring='accuracy')
grid_search_xgb.fit(features_train, labels_train)

# הדפסת ההייפר-פרמטרים האופטימליים עבור XGBoost
print(f'Best Hyperparameters for XGBoost: {grid_search_xgb.best_params_}')
print(f'Best Accuracy for XGBoost: {grid_search_xgb.best_score_}')


# אימון המודל האופטימלי על סט האימון כולו עבור XGBoost
best_xgb = grid_search_xgb.best_estimator_
best_xgb.fit(features_train, labels_train)

# בדיקה על סט הוולידציה עבור XGBoost
labels_val_pred_xgb = best_xgb.predict(features_val)
val_accuracy_xgb = accuracy_score(labels_val, labels_val_pred_xgb)
print(f'Validation Accuracy for XGBoost: {val_accuracy_xgb}')

# יצירת מטריצת בלבול והצגתה על סט הוולידציה עבור XGBoost
cm_xgb = confusion_matrix(labels_val, labels_val_pred_xgb)
disp_xgb = ConfusionMatrixDisplay(confusion_matrix=cm_xgb)
disp_xgb.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix - Validation Set for XGBoost')
plt.show()

# הגדרת טווח הערכים להייפר-פרמטרים עבור Decision Tree
param_grid_dt = {
    'max_depth': [3, 5, 7, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'criterion': ['gini', 'entropy']
}

# יצירת מודל Decision Tree
dt_model = DecisionTreeClassifier(random_state=42)

# בדיקה על סט האימון עם הייפר פרמטרים שונים על מנת להתאים את ההייפר פרמטרים הטובים ביותר על פי ציון accuracy
grid_search_dt = GridSearchCV(estimator=dt_model, param_grid=param_grid_dt, cv=10, scoring='accuracy')
grid_search_dt.fit(features_train, labels_train)

# הדפסת ההייפר-פרמטרים האופטימליים עבור Decision Tree
print(f'Best Hyperparameters for Decision Tree: {grid_search_dt.best_params_}')
print(f'Best Accuracy for Decision Tree: {grid_search_dt.best_score_}')

# אימון המודל האופטימלי על סט האימון כולו עבור Decision Tree
best_dt = grid_search_dt.best_estimator_
best_dt.fit(features_train, labels_train)

# בדיקה על סט הוולידציה עבור Decision Tree
labels_val_pred_dt = best_dt.predict(features_val)
val_accuracy_dt = accuracy_score(labels_val, labels_val_pred_dt)
print(f'Validation Accuracy for Decision Tree: {val_accuracy_dt}')

# יצירת מטריצת בלבול והצגתה על סט הוולידציה עבור Decision Tree
cm_dt = confusion_matrix(labels_val, labels_val_pred_dt)
disp_dt = ConfusionMatrixDisplay(confusion_matrix=cm_dt)
disp_dt.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix - Validation Set for Decision Tree')
plt.show()

# השוואת תוצאות
accuracies = {
    'KNN': val_accuracy,
    'XGBoost': val_accuracy_xgb,
    'Decision Tree': val_accuracy_dt
}

plt.figure(figsize=(10, 5))
plt.bar(accuracies.keys(), accuracies.values(), color=['blue', 'green', 'purple'])
plt.xlabel('Model')
plt.ylabel('Validation Accuracy')
plt.title('Validation Accuracy Comparison')
plt.show()

"""ניתן לראות כי מודל Xgboost הוא בעל הציון הטוב ביותר ולכן נקח אותו לצורך חיזוי התוצאות על סט הבדיקה (Test)"""

# בדיקה על סט הבדיקה עבור XGBoost
labels_test_pred_xgb = best_xgb.predict(features_test)
test_accuracy_xgb = accuracy_score(labels_test, labels_test_pred_xgb)
print(f'Test Accuracy for XGBoost: {test_accuracy_xgb}')

# יצירת מטריצת בלבול והצגתה על סט הבדיקה עבור XGBoost
cm_test_xgb = confusion_matrix(labels_test, labels_test_pred_xgb)
disp_test_xgb = ConfusionMatrixDisplay(confusion_matrix=cm_test_xgb)
disp_test_xgb.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix - Test Set for XGBoost')
plt.show()

"""לסיכום ניתן לראות כי מודל XGboost לאחר התאמת הייפר פרמטרים הוא המודל בעל החיזוי הטוב ביותר מבים שלושת המודלים שנבדקו."""